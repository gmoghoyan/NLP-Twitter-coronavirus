{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "723e0aad",
   "metadata": {},
   "source": [
    "# IST664 NLP\n",
    "# Group Project \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c567c87",
   "metadata": {},
   "source": [
    "# Topic: Corona virus NLP\n",
    "\n",
    "# Mars 2022\n",
    "\n",
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f2067b",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "838378a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import seaborn as sn\n",
    "import wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a93ddc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('Corona_NLP_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08a7ff15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>44953</td>\n",
       "      <td>NYC</td>\n",
       "      <td>02-03-2020</td>\n",
       "      <td>TRENDING: New Yorkers encounter empty supermar...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>44954</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>02-03-2020</td>\n",
       "      <td>When I couldn't find hand sanitizer at Fred Me...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>44955</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02-03-2020</td>\n",
       "      <td>Find out how you can protect yourself and love...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>44956</td>\n",
       "      <td>Chicagoland</td>\n",
       "      <td>02-03-2020</td>\n",
       "      <td>#Panic buying hits #NewYork City as anxious sh...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>44957</td>\n",
       "      <td>Melbourne, Victoria</td>\n",
       "      <td>03-03-2020</td>\n",
       "      <td>#toiletpaper #dunnypaper #coronavirus #coronav...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserName  ScreenName             Location     TweetAt  \\\n",
       "0         1       44953                  NYC  02-03-2020   \n",
       "1         2       44954          Seattle, WA  02-03-2020   \n",
       "2         3       44955                  NaN  02-03-2020   \n",
       "3         4       44956          Chicagoland  02-03-2020   \n",
       "4         5       44957  Melbourne, Victoria  03-03-2020   \n",
       "\n",
       "                                       OriginalTweet           Sentiment  \n",
       "0  TRENDING: New Yorkers encounter empty supermar...  Extremely Negative  \n",
       "1  When I couldn't find hand sanitizer at Fred Me...            Positive  \n",
       "2  Find out how you can protect yourself and love...  Extremely Positive  \n",
       "3  #Panic buying hits #NewYork City as anxious sh...            Negative  \n",
       "4  #toiletpaper #dunnypaper #coronavirus #coronav...             Neutral  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81c1f009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3798"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1abd6a",
   "metadata": {},
   "source": [
    "# Data pre-processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81e3a1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only need the tweets and associated sentiment\n",
    "tweets_df = pd.read_csv('Corona_NLP_train.csv', encoding='latin-1')\n",
    "tweets_df = tweets_df[['OriginalTweet', 'Sentiment']]\n",
    "\n",
    "test_df = pd.read_csv('Corona_NLP_test.csv')\n",
    "test_df = test_df[['OriginalTweet', 'Sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12151436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRENDING: New Yorkers encounter empty supermar...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I couldn't find hand sanitizer at Fred Me...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Find out how you can protect yourself and love...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Panic buying hits #NewYork City as anxious sh...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#toiletpaper #dunnypaper #coronavirus #coronav...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3793</th>\n",
       "      <td>Meanwhile In A Supermarket in Israel -- People...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>Did you panic buy a lot of non-perishable item...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>Asst Prof of Economics @cconces was on @NBCPhi...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3796</th>\n",
       "      <td>Gov need to do somethings instead of biar je r...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3797</th>\n",
       "      <td>I and @ForestandPaper members are committed to...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3798 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          OriginalTweet           Sentiment\n",
       "0     TRENDING: New Yorkers encounter empty supermar...  Extremely Negative\n",
       "1     When I couldn't find hand sanitizer at Fred Me...            Positive\n",
       "2     Find out how you can protect yourself and love...  Extremely Positive\n",
       "3     #Panic buying hits #NewYork City as anxious sh...            Negative\n",
       "4     #toiletpaper #dunnypaper #coronavirus #coronav...             Neutral\n",
       "...                                                 ...                 ...\n",
       "3793  Meanwhile In A Supermarket in Israel -- People...            Positive\n",
       "3794  Did you panic buy a lot of non-perishable item...            Negative\n",
       "3795  Asst Prof of Economics @cconces was on @NBCPhi...             Neutral\n",
       "3796  Gov need to do somethings instead of biar je r...  Extremely Negative\n",
       "3797  I and @ForestandPaper members are committed to...  Extremely Positive\n",
       "\n",
       "[3798 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cec98a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRENDING: New Yorkers encounter empty supermar...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I couldn't find hand sanitizer at Fred Me...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Find out how you can protect yourself and love...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Panic buying hits #NewYork City as anxious sh...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#toiletpaper #dunnypaper #coronavirus #coronav...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       OriginalTweet           Sentiment\n",
       "0  TRENDING: New Yorkers encounter empty supermar...  Extremely Negative\n",
       "1  When I couldn't find hand sanitizer at Fred Me...            Positive\n",
       "2  Find out how you can protect yourself and love...  Extremely Positive\n",
       "3  #Panic buying hits #NewYork City as anxious sh...            Negative\n",
       "4  #toiletpaper #dunnypaper #coronavirus #coronav...             Neutral"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16d29b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    41157\n",
      "Name: OriginalTweet, dtype: int64\n",
      "False    41157\n",
      "Name: Sentiment, dtype: int64\n",
      "\n",
      "False    3798\n",
      "Name: OriginalTweet, dtype: int64\n",
      "False    3798\n",
      "Name: Sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for null values\n",
    "for column in tweets_df.columns:\n",
    "    print(tweets_df[column].isnull().value_counts())\n",
    "print()  \n",
    "for column in test_df.columns:\n",
    "    print(test_df[column].isnull().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43e236e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    41157\n",
      "dtype: int64\n",
      "\n",
      "False    3798\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate values\n",
    "print(tweets_df.duplicated().value_counts())\n",
    "print()\n",
    "print(test_df.duplicated().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "718332a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\adjeg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nltk.download('stopwords')\n",
    "#ps = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "989538a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspellchecker in c:\\users\\adjeg\\anaconda3\\lib\\site-packages (0.6.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspellchecker \n",
    "from spellchecker import SpellChecker\n",
    "spell = SpellChecker()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2fee75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d45bb455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "puncs_ = string.punctuation.replace('@','')\n",
    "puncs = puncs_.replace('#','')\n",
    "puncs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fc8d311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'      @ the springs theatre httpstcoaertookvav'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '           @ the springs theatre httpstcoaertookvav'\n",
    "mytext = \" \".join(s.split(\"  \"))\n",
    "mytext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05129207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def textClean(text):\n",
    "    # convert to lowercase\n",
    "    lower = [char.lower() for char in text if char not in puncs]\n",
    "    lower = ''.join(lower)\n",
    "    lower = ' '.join(lower.split())\n",
    "    \n",
    "    # delete @mentions and #tags\n",
    "    for char in lower:\n",
    "        if lower.find('@')==-1 and lower.find('#')==-1: # break loop once @ and # is over\n",
    "            break\n",
    "        if (char=='@' or char=='#'):\n",
    "            try:\n",
    "                char_index = lower.index(char)\n",
    "            except ValueError:\n",
    "                #print(lower)\n",
    "                break\n",
    "            del_word = ''\n",
    "            while char not in string.whitespace:\n",
    "                del_word = del_word+lower[char_index]\n",
    "                char_index = char_index + 1\n",
    "                try:\n",
    "                    char = lower[char_index] #trying for indexerror incase it is the last character of string\n",
    "                except IndexError:\n",
    "                    char = ' '\n",
    "                except:\n",
    "                    print(\"Something else went wrong\")\n",
    "            lower = lower.replace(del_word,'',1)\n",
    "    lower = [char for char in lower if char not in string.punctuation and char not in string.digits]\n",
    "    lower = ''.join(lower)\n",
    "    \n",
    "    tokens = word_tokenize(lower)\n",
    "    nohttp = [word for word in tokens if word[0:4]!='http']\n",
    "    nostop = [word for word in nohttp if word not in stopwords.words('english')]\n",
    "    return nostop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18726d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...\n",
      "1    advice Talk to your neighbours family to excha...\n",
      "2    Coronavirus Australia: Woolworths to give elde...\n",
      "3    My food stock is not the only one which is emp...\n",
      "4    Me, ready to go at supermarket during the #COV...\n",
      "5    As news of the regionÃ‚Â’s first confirmed COVID...\n",
      "6    Cashier at grocery store was sharing his insig...\n",
      "7    Was at the supermarket today. Didn't buy toile...\n",
      "8    Due to COVID-19 our retail store and classroom...\n",
      "9    For corona prevention,we should stop to buy th...\n",
      "Name: OriginalTweet, dtype: object\n",
      "[]\n",
      "['advice', 'talk', 'neighbours', 'family', 'exchange', 'phone', 'numbers', 'create', 'contact', 'list', 'phone', 'numbers', 'neighbours', 'schools', 'employer', 'chemist', 'gp', 'set', 'online', 'shopping', 'accounts', 'poss', 'adequate', 'supplies', 'regular', 'meds', 'order']\n",
      "['coronavirus', 'australia', 'woolworths', 'give', 'elderly', 'disabled', 'dedicated', 'shopping', 'hours', 'amid', 'covid', 'outbreak']\n",
      "['food', 'stock', 'one', 'empty', 'please', 'dont', 'panic', 'enough', 'food', 'everyone', 'take', 'need', 'stay', 'calm', 'stay', 'safe']\n",
      "['ready', 'go', 'supermarket', 'outbreak', 'im', 'paranoid', 'food', 'stock', 'litteraly', 'empty', 'serious', 'thing', 'please', 'dont', 'panic', 'causes', 'shortage']\n",
      "['news', 'regionÃ¢\\x92s', 'first', 'confirmed', 'covid', 'case', 'came', 'sullivan', 'county', 'last', 'week', 'people', 'flocked', 'area', 'stores', 'purchase', 'cleaning', 'supplies', 'hand', 'sanitizer', 'food', 'toilet', 'paper', 'goods', 'reports']\n",
      "['cashier', 'grocery', 'store', 'sharing', 'insights', 'prove', 'credibility', 'commented', 'im', 'civics', 'class', 'know', 'im', 'talking']\n",
      "['supermarket', 'today', 'didnt', 'buy', 'toilet', 'paper']\n",
      "['due', 'covid', 'retail', 'store', 'classroom', 'atlanta', 'open', 'walkin', 'business', 'classes', 'next', 'two', 'weeks', 'beginning', 'monday', 'march', 'continue', 'process', 'online', 'phone', 'orders', 'normal', 'thank', 'understanding']\n",
      "['corona', 'preventionwe', 'stop', 'buy', 'things', 'cash', 'use', 'online', 'payment', 'methods', 'corona', 'spread', 'notes', 'also', 'prefer', 'online', 'shopping', 'home', 'time', 'fight', 'covid']\n"
     ]
    }
   ],
   "source": [
    "print(tweets_df.OriginalTweet[0:10])\n",
    "tweets_df.OriginalTweet[0:10].apply(textClean)\n",
    "temp_list = tweets_df.OriginalTweet[0:10].apply(textClean)\n",
    "for each_list in temp_list:\n",
    "    print(each_list)#for word in each_list:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e727e5d5",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78e5d6a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41157, 39097)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(analyzer=textClean)\n",
    "message = vectorizer.fit_transform(tweets_df['OriginalTweet'])\n",
    "message.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6bc6a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into 80% training and 20% testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(message,tweets_df.Sentiment,test_size=0.20,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbb4fcf",
   "metadata": {},
   "source": [
    "## Naive Bayes MultinomialNB "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05500c10",
   "metadata": {},
   "source": [
    "## Naive Bayes on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa1ecc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and train the Naive Bayes Classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB().fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c6628e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Positive' 'Positive' 'Positive' ... 'Positive' 'Neutral' 'Positive']\n",
      "['Neutral' 'Negative' 'Positive' ... 'Neutral' 'Neutral' 'Positive']\n"
     ]
    }
   ],
   "source": [
    "print(classifier.predict(xtest))\n",
    "print(ytest.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5330d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Extremely Negative       0.88      0.66      0.76      4387\n",
      "Extremely Positive       0.83      0.72      0.77      5293\n",
      "          Negative       0.70      0.78      0.74      7931\n",
      "           Neutral       0.93      0.55      0.69      6187\n",
      "          Positive       0.63      0.87      0.73      9127\n",
      "\n",
      "          accuracy                           0.73     32925\n",
      "         macro avg       0.79      0.71      0.74     32925\n",
      "      weighted avg       0.77      0.73      0.73     32925\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      " [[2909   32 1033   36  377]\n",
      " [  21 3791  166   20 1295]\n",
      " [ 257  152 6180  110 1232]\n",
      " [  59  139  887 3372 1730]\n",
      " [  64  477  575   99 7912]]\n",
      "Accuracy: \n",
      " 0.7339104024297646\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the training data set\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "pred = classifier.predict(xtrain)\n",
    "print(classification_report(ytrain, pred))\n",
    "print()\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(ytrain, pred))\n",
    "print(\"Accuracy: \\n\", accuracy_score(ytrain, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "200a8d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Extremely Negative       0.59      0.39      0.47      1094\n",
      "Extremely Positive       0.56      0.44      0.49      1331\n",
      "          Negative       0.44      0.50      0.47      1986\n",
      "           Neutral       0.67      0.34      0.45      1526\n",
      "          Positive       0.41      0.61      0.49      2295\n",
      "\n",
      "          accuracy                           0.48      8232\n",
      "         macro avg       0.53      0.46      0.47      8232\n",
      "      weighted avg       0.51      0.48      0.47      8232\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 422    8  511   26  127]\n",
      " [   7  589   78   23  634]\n",
      " [ 209   72 1000   81  624]\n",
      " [  30   44  313  518  621]\n",
      " [  48  336  395  123 1393]]\n",
      "Accuracy: \n",
      " 0.47643343051506315\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the testing data set\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "pred = classifier.predict(xtest)\n",
    "print(classification_report(ytest, pred))\n",
    "print()\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(ytest, pred))\n",
    "print(\"Accuracy: \\n\", accuracy_score(ytest, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9711808b",
   "metadata": {},
   "source": [
    "## Naives Bayes on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f90c1d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3798, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22149a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3798, 39097)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message2 = vectorizer.transform(test_df['OriginalTweet'])\n",
    "message2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2fa55dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3798x39097 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 58205 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48611d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Negative' 'Positive' 'Extremely Positive' ... 'Neutral'\n",
      " 'Extremely Negative' 'Positive']\n",
      "0       Extremely Negative\n",
      "1                 Positive\n",
      "2       Extremely Positive\n",
      "3                 Negative\n",
      "4                  Neutral\n",
      "               ...        \n",
      "3793              Positive\n",
      "3794              Negative\n",
      "3795               Neutral\n",
      "3796    Extremely Negative\n",
      "3797    Extremely Positive\n",
      "Name: Sentiment, Length: 3798, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(classifier.predict(message2))\n",
    "print(test_df.Sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8635e4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Extremely Negative       0.59      0.30      0.39       592\n",
      "Extremely Positive       0.63      0.35      0.45       599\n",
      "          Negative       0.44      0.51      0.47      1041\n",
      "           Neutral       0.66      0.21      0.31       619\n",
      "          Positive       0.37      0.69      0.48       947\n",
      "\n",
      "          accuracy                           0.45      3798\n",
      "         macro avg       0.54      0.41      0.42      3798\n",
      "      weighted avg       0.51      0.45      0.43      3798\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      " [[175   5 328   4  80]\n",
      " [  5 211  34   2 347]\n",
      " [ 83  21 529  38 370]\n",
      " [  9  15 158 127 310]\n",
      " [ 26  84 164  21 652]]\n",
      "Accuracy: \n",
      " 0.4460242232754081\n"
     ]
    }
   ],
   "source": [
    "pred = classifier.predict(message2)\n",
    "print(classification_report(test_df.Sentiment, pred))\n",
    "print()\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(test_df.Sentiment, pred))\n",
    "print(\"Accuracy: \\n\", accuracy_score(test_df.Sentiment, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b8fd65",
   "metadata": {},
   "source": [
    "# Building LinearSVC model (Linear SVM) with sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4a808a",
   "metadata": {},
   "source": [
    "## Train a LinearSVC classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a02029d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adjeg\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the LinearSVC module\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# initialize the LinearSVC model\n",
    "svm_clf = LinearSVC(C=1)\n",
    "\n",
    "# use the training data to train the model\n",
    "svm_clf.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49db14ab",
   "metadata": {},
   "source": [
    "### SVM On Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b76f14ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9774335611237661"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the classifier on the train data set, print accuracy score\n",
    "\n",
    "svm_clf.score(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "710ab0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4367    0   19    1    0]\n",
      " [   0 5250    4    1   38]\n",
      " [  46    9 7631  127  118]\n",
      " [   2    2   51 6093   39]\n",
      " [   5   72  120   89 8841]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4387\n",
      "           1       0.98      0.99      0.99      5293\n",
      "           2       0.98      0.96      0.97      7931\n",
      "           3       0.97      0.98      0.98      6187\n",
      "           4       0.98      0.97      0.97      9127\n",
      "\n",
      "    accuracy                           0.98     32925\n",
      "   macro avg       0.98      0.98      0.98     32925\n",
      "weighted avg       0.98      0.98      0.98     32925\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print confusion matrix and classification report\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = svm_clf.predict(xtrain)\n",
    "cm=confusion_matrix(ytrain, y_pred)\n",
    "print(cm)\n",
    "print()\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = ['0','1','2','3','4']\n",
    "print(classification_report(ytrain, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "88784546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.05606394 -3.34168423  0.97835874 -1.92400256 -1.51729638]\n"
     ]
    }
   ],
   "source": [
    "## get the confidence scores for all train examples from each of the five binary classifiers\n",
    "svm_confidence_scores = svm_clf.decision_function(xtrain)\n",
    "## get the confidence score for the first test example\n",
    "print(svm_confidence_scores[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d9c839",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2292d05c",
   "metadata": {},
   "source": [
    "### SVM on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2f065fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5668124392614189"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the classifier on the test data set, print accuracy score\n",
    "\n",
    "svm_clf.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b7910cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 681   13  292   42   66]\n",
      " [   5  865   53   35  373]\n",
      " [ 337   65  903  301  380]\n",
      " [  22   14  174 1084  232]\n",
      " [  58  381  387  336 1133]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62      1094\n",
      "           1       0.65      0.65      0.65      1331\n",
      "           2       0.50      0.45      0.48      1986\n",
      "           3       0.60      0.71      0.65      1526\n",
      "           4       0.52      0.49      0.51      2295\n",
      "\n",
      "    accuracy                           0.57      8232\n",
      "   macro avg       0.58      0.59      0.58      8232\n",
      "weighted avg       0.56      0.57      0.56      8232\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print confusion matrix and classification report\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = svm_clf.predict(xtest)\n",
    "cm=confusion_matrix(ytest, y_pred)\n",
    "print(cm)\n",
    "print()\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = ['0','1','2','3','4']\n",
    "print(classification_report(ytest, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b5431d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.69203407 -2.11142223 -0.94205552  0.41737698 -0.29734308]\n"
     ]
    }
   ],
   "source": [
    "## get the confidence scores for all test examples from each of the five binary classifiers\n",
    "svm_confidence_scores = svm_clf.decision_function(xtest)\n",
    "## get the confidence score for the first test example\n",
    "print(svm_confidence_scores[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fda481",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
